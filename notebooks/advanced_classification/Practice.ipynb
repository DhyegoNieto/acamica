{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine - SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# NLP\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# SVM --> Support Vector Classification\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "\n",
    "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)\n",
    "\n",
    "twenty_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando TfidfVectorizer se crea una matriz con la relevancia de las palabras en relación a los diferentes documentos del dataset de entrenamiento\n",
    "\n",
    "**use_idf : boolean (default=True): Enable inverse-document-frequency reweighting.(???)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2257, 35788)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tf = TfidfVectorizer(use_idf=False).fit_transform(twenty_train.data)\n",
    "X_train_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tf.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**El objetivo de está clasificación es usar el dataset de noticias de diferentes categorias (['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med'])\n",
    "Obtener la relevancia de las palabras y clasificarlas por categoria\n",
    "Se usa un Pipeline para entrenar el Tfidf (Term Frequency Inverse Document Frequency) y luego realizar la predicción con SVC (Support Vector Classifier)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline: \n",
    "**Secuencialmente aplica transformaciones y finalmente un estimador. Los pasos intermedios deben implementar los métodos _fit_ y _transform_, el estimador final solo requiere implementar el método _fit_.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('tfidf' , TfidfVectorizer()), ('classifier', SVC(kernel='linear'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenando (tfidf o classifier ????)\n",
    "text_clf.fit(twenty_train.data, twenty_train.target)\n",
    "\n",
    "predicted = text_clf.predict(twenty_test.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calcular accuracy:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9207723035952063"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer()\n",
    "X_train = tf_idf.fit_transform(twenty_train.data)\n",
    "X_test = tf_idf.transform(twenty_test.data)\n",
    "y_train = twenty_train.target\n",
    "y_test = twenty_test.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soft Voting (allowing probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC 0.9207723035952063\n",
      "SGDClassifier 0.9181091877496671\n",
      "DecisionTreeClassifier 0.7137150466045273\n",
      "VotingClassifier 0.8994673768308922\n"
     ]
    }
   ],
   "source": [
    "svc_clf = SVC(kernel='linear', probability=True)\n",
    "sgd_clf = SGDClassifier(loss='log')\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "voting_clf = VotingClassifier(estimators=[('svc', svc_clf), ('sgd', sgd_clf), ('tree', tree_clf)], voting='soft')\n",
    "\n",
    "for clf in (svc_clf, sgd_clf, tree_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_predict = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard voting (doesn't allow probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC 0.9207723035952063\n",
      "SGDClassifier 0.9267643142476698\n",
      "DecisionTreeClassifier 0.7210386151797603\n",
      "VotingClassifier 0.9254327563249002\n"
     ]
    }
   ],
   "source": [
    "svc_clf = SVC(kernel='linear')\n",
    "sgd_clf = SGDClassifier()\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "voting_clf = VotingClassifier(estimators=[('svc', svc_clf), ('sgd', sgd_clf), ('tree', tree_clf)], voting='hard')\n",
    "\n",
    "for clf in (svc_clf, sgd_clf, tree_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_predict = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging (Bootstrap Agreggating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7217043941411452"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implements several classifiers (the same type e.g. _DecisionTree - multiple trees makes a forest a RandomForest_), each classifier is trained using a bunch of training instances, then the next classifier is trained with the same or different instances, finally a Voting is done.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7989347536617842"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=200, n_jobs=-1)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8135818908122503"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rnd_clf = RandomForestClassifier(n_estimators=200, n_jobs=-1)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "y_pred = rnd_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost\n",
    "**Boosting multiple _weak_ estimators learn from the error of the previous estimator** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=1.0, n_estimators=1500, random_state=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), n_estimators=1500, algorithm='SAMME.R')\n",
    "ada_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7782956058588548"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = ada_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XgBoost (Extreme Gradient Boost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install xgboost\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=None,\n",
       "       objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf = XGBClassifier()\n",
    "xgb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8681757656458056"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = xgb_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LigthGBM (Ligth Gradient Boosting Machine - Microsoft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c conda-forge lightgbm\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_logloss: 1.27964\n",
      "[2]\tvalid_0's multi_logloss: 1.19555\n",
      "[3]\tvalid_0's multi_logloss: 1.12404\n",
      "[4]\tvalid_0's multi_logloss: 1.06169\n",
      "[5]\tvalid_0's multi_logloss: 1.00366\n",
      "[6]\tvalid_0's multi_logloss: 0.952655\n",
      "[7]\tvalid_0's multi_logloss: 0.909478\n",
      "[8]\tvalid_0's multi_logloss: 0.869212\n",
      "[9]\tvalid_0's multi_logloss: 0.8343\n",
      "[10]\tvalid_0's multi_logloss: 0.80072\n",
      "[11]\tvalid_0's multi_logloss: 0.771599\n",
      "[12]\tvalid_0's multi_logloss: 0.743307\n",
      "[13]\tvalid_0's multi_logloss: 0.71649\n",
      "[14]\tvalid_0's multi_logloss: 0.691686\n",
      "[15]\tvalid_0's multi_logloss: 0.667471\n",
      "[16]\tvalid_0's multi_logloss: 0.64493\n",
      "[17]\tvalid_0's multi_logloss: 0.625319\n",
      "[18]\tvalid_0's multi_logloss: 0.607054\n",
      "[19]\tvalid_0's multi_logloss: 0.589882\n",
      "[20]\tvalid_0's multi_logloss: 0.573306\n",
      "[21]\tvalid_0's multi_logloss: 0.557896\n",
      "[22]\tvalid_0's multi_logloss: 0.545648\n",
      "[23]\tvalid_0's multi_logloss: 0.531141\n",
      "[24]\tvalid_0's multi_logloss: 0.518963\n",
      "[25]\tvalid_0's multi_logloss: 0.50745\n",
      "[26]\tvalid_0's multi_logloss: 0.495493\n",
      "[27]\tvalid_0's multi_logloss: 0.485438\n",
      "[28]\tvalid_0's multi_logloss: 0.477023\n",
      "[29]\tvalid_0's multi_logloss: 0.467908\n",
      "[30]\tvalid_0's multi_logloss: 0.460349\n",
      "[31]\tvalid_0's multi_logloss: 0.452824\n",
      "[32]\tvalid_0's multi_logloss: 0.44535\n",
      "[33]\tvalid_0's multi_logloss: 0.440778\n",
      "[34]\tvalid_0's multi_logloss: 0.434789\n",
      "[35]\tvalid_0's multi_logloss: 0.429554\n",
      "[36]\tvalid_0's multi_logloss: 0.424731\n",
      "[37]\tvalid_0's multi_logloss: 0.420727\n",
      "[38]\tvalid_0's multi_logloss: 0.415916\n",
      "[39]\tvalid_0's multi_logloss: 0.410506\n",
      "[40]\tvalid_0's multi_logloss: 0.405929\n",
      "[41]\tvalid_0's multi_logloss: 0.401275\n",
      "[42]\tvalid_0's multi_logloss: 0.397139\n",
      "[43]\tvalid_0's multi_logloss: 0.393724\n",
      "[44]\tvalid_0's multi_logloss: 0.391484\n",
      "[45]\tvalid_0's multi_logloss: 0.388863\n",
      "[46]\tvalid_0's multi_logloss: 0.386483\n",
      "[47]\tvalid_0's multi_logloss: 0.383164\n",
      "[48]\tvalid_0's multi_logloss: 0.380257\n",
      "[49]\tvalid_0's multi_logloss: 0.37788\n",
      "[50]\tvalid_0's multi_logloss: 0.374958\n",
      "[51]\tvalid_0's multi_logloss: 0.372049\n",
      "[52]\tvalid_0's multi_logloss: 0.369979\n",
      "[53]\tvalid_0's multi_logloss: 0.367174\n",
      "[54]\tvalid_0's multi_logloss: 0.364912\n",
      "[55]\tvalid_0's multi_logloss: 0.363081\n",
      "[56]\tvalid_0's multi_logloss: 0.361941\n",
      "[57]\tvalid_0's multi_logloss: 0.360706\n",
      "[58]\tvalid_0's multi_logloss: 0.359495\n",
      "[59]\tvalid_0's multi_logloss: 0.358577\n",
      "[60]\tvalid_0's multi_logloss: 0.357301\n",
      "[61]\tvalid_0's multi_logloss: 0.355682\n",
      "[62]\tvalid_0's multi_logloss: 0.354078\n",
      "[63]\tvalid_0's multi_logloss: 0.353084\n",
      "[64]\tvalid_0's multi_logloss: 0.352493\n",
      "[65]\tvalid_0's multi_logloss: 0.351394\n",
      "[66]\tvalid_0's multi_logloss: 0.350848\n",
      "[67]\tvalid_0's multi_logloss: 0.349802\n",
      "[68]\tvalid_0's multi_logloss: 0.349381\n",
      "[69]\tvalid_0's multi_logloss: 0.348103\n",
      "[70]\tvalid_0's multi_logloss: 0.349025\n",
      "[71]\tvalid_0's multi_logloss: 0.348686\n",
      "[72]\tvalid_0's multi_logloss: 0.34785\n",
      "[73]\tvalid_0's multi_logloss: 0.347273\n",
      "[74]\tvalid_0's multi_logloss: 0.347436\n",
      "[75]\tvalid_0's multi_logloss: 0.345939\n",
      "[76]\tvalid_0's multi_logloss: 0.345246\n",
      "[77]\tvalid_0's multi_logloss: 0.345839\n",
      "[78]\tvalid_0's multi_logloss: 0.345338\n",
      "[79]\tvalid_0's multi_logloss: 0.344877\n",
      "[80]\tvalid_0's multi_logloss: 0.345054\n",
      "[81]\tvalid_0's multi_logloss: 0.34475\n",
      "[82]\tvalid_0's multi_logloss: 0.345304\n",
      "[83]\tvalid_0's multi_logloss: 0.345114\n",
      "[84]\tvalid_0's multi_logloss: 0.345198\n",
      "[85]\tvalid_0's multi_logloss: 0.34532\n",
      "[86]\tvalid_0's multi_logloss: 0.34543\n",
      "[87]\tvalid_0's multi_logloss: 0.34583\n",
      "[88]\tvalid_0's multi_logloss: 0.346389\n",
      "[89]\tvalid_0's multi_logloss: 0.346567\n",
      "[90]\tvalid_0's multi_logloss: 0.346937\n",
      "[91]\tvalid_0's multi_logloss: 0.347928\n",
      "[92]\tvalid_0's multi_logloss: 0.347862\n",
      "[93]\tvalid_0's multi_logloss: 0.34812\n",
      "[94]\tvalid_0's multi_logloss: 0.348218\n",
      "[95]\tvalid_0's multi_logloss: 0.348454\n",
      "[96]\tvalid_0's multi_logloss: 0.349086\n",
      "[97]\tvalid_0's multi_logloss: 0.34822\n",
      "[98]\tvalid_0's multi_logloss: 0.348068\n",
      "[99]\tvalid_0's multi_logloss: 0.348052\n",
      "[100]\tvalid_0's multi_logloss: 0.348362\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "        n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm = lgb.LGBMClassifier()\n",
    "gbm.fit(X_train, y_train, eval_set=[(X_test, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8808255659121171"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gbm.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking\n",
    "\n",
    "**uses the results from multiple estimators as features, to process it and then make it's own predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install vecstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [classification]\n",
      "n_classes:    [4]\n",
      "metric:       [accuracy_score]\n",
      "variant:      [A]\n",
      "n_estimators: [2]\n",
      "\n",
      "estimator  0: [xgb: XGBClassifier]\n",
      "    fold  0:  [0.90619469]\n",
      "    fold  1:  [0.92730496]\n",
      "    fold  2:  [0.90780142]\n",
      "    fold  3:  [0.90070922]\n",
      "    ----\n",
      "    MEAN:     [0.91050257] + [0.01005092]\n",
      "\n",
      "estimator  1: [ada: AdaBoostClassifier]\n",
      "    fold  0:  [0.85309735]\n",
      "    fold  1:  [0.86170213]\n",
      "    fold  2:  [0.81382979]\n",
      "    fold  3:  [0.84929078]\n",
      "    ----\n",
      "    MEAN:     [0.84448001] + [0.01825815]\n",
      "\n",
      "Train set was detected.\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [xgb: XGBClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [ada: AdaBoostClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [xgb: XGBClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [ada: AdaBoostClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from vecstack import StackingTransformer\n",
    "\n",
    "estimators = [('xgb', xgb_clf), ('ada', ada_clf)]\n",
    "\n",
    "# StackingTransformer\n",
    "stack = StackingTransformer(estimators, regression=False, verbose=2)\n",
    "\n",
    "# Fit\n",
    "stack = stack.fit(X_train, y_train)\n",
    "\n",
    "# stacked features\n",
    "S_train = stack.transform(X_train)\n",
    "S_test = stack.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_logloss: 1.24018\n",
      "[2]\tvalid_0's multi_logloss: 1.12659\n",
      "[3]\tvalid_0's multi_logloss: 1.03325\n",
      "[4]\tvalid_0's multi_logloss: 0.955259\n",
      "[5]\tvalid_0's multi_logloss: 0.889316\n",
      "[6]\tvalid_0's multi_logloss: 0.833101\n",
      "[7]\tvalid_0's multi_logloss: 0.7849\n",
      "[8]\tvalid_0's multi_logloss: 0.743402\n",
      "[9]\tvalid_0's multi_logloss: 0.707574\n",
      "[10]\tvalid_0's multi_logloss: 0.676589\n",
      "[11]\tvalid_0's multi_logloss: 0.649767\n",
      "[12]\tvalid_0's multi_logloss: 0.626259\n",
      "[13]\tvalid_0's multi_logloss: 0.60591\n",
      "[14]\tvalid_0's multi_logloss: 0.588312\n",
      "[15]\tvalid_0's multi_logloss: 0.573117\n",
      "[16]\tvalid_0's multi_logloss: 0.559916\n",
      "[17]\tvalid_0's multi_logloss: 0.548567\n",
      "[18]\tvalid_0's multi_logloss: 0.538765\n",
      "[19]\tvalid_0's multi_logloss: 0.530392\n",
      "[20]\tvalid_0's multi_logloss: 0.523268\n",
      "[21]\tvalid_0's multi_logloss: 0.51724\n",
      "[22]\tvalid_0's multi_logloss: 0.512056\n",
      "[23]\tvalid_0's multi_logloss: 0.507702\n",
      "[24]\tvalid_0's multi_logloss: 0.504089\n",
      "[25]\tvalid_0's multi_logloss: 0.501119\n",
      "[26]\tvalid_0's multi_logloss: 0.498708\n",
      "[27]\tvalid_0's multi_logloss: 0.496776\n",
      "[28]\tvalid_0's multi_logloss: 0.495261\n",
      "[29]\tvalid_0's multi_logloss: 0.494126\n",
      "[30]\tvalid_0's multi_logloss: 0.493294\n",
      "[31]\tvalid_0's multi_logloss: 0.49272\n",
      "[32]\tvalid_0's multi_logloss: 0.492363\n",
      "[33]\tvalid_0's multi_logloss: 0.49219\n",
      "[34]\tvalid_0's multi_logloss: 0.49217\n",
      "[35]\tvalid_0's multi_logloss: 0.492279\n",
      "[36]\tvalid_0's multi_logloss: 0.492493\n",
      "[37]\tvalid_0's multi_logloss: 0.492794\n",
      "[38]\tvalid_0's multi_logloss: 0.493167\n",
      "[39]\tvalid_0's multi_logloss: 0.493596\n",
      "[40]\tvalid_0's multi_logloss: 0.494071\n",
      "[41]\tvalid_0's multi_logloss: 0.494582\n",
      "[42]\tvalid_0's multi_logloss: 0.495121\n",
      "[43]\tvalid_0's multi_logloss: 0.495681\n",
      "[44]\tvalid_0's multi_logloss: 0.496257\n",
      "[45]\tvalid_0's multi_logloss: 0.496844\n",
      "[46]\tvalid_0's multi_logloss: 0.497439\n",
      "[47]\tvalid_0's multi_logloss: 0.498039\n",
      "[48]\tvalid_0's multi_logloss: 0.498641\n",
      "[49]\tvalid_0's multi_logloss: 0.49923\n",
      "[50]\tvalid_0's multi_logloss: 0.499821\n",
      "[51]\tvalid_0's multi_logloss: 0.500412\n",
      "[52]\tvalid_0's multi_logloss: 0.501003\n",
      "[53]\tvalid_0's multi_logloss: 0.501593\n",
      "[54]\tvalid_0's multi_logloss: 0.502174\n",
      "[55]\tvalid_0's multi_logloss: 0.502656\n",
      "[56]\tvalid_0's multi_logloss: 0.503233\n",
      "[57]\tvalid_0's multi_logloss: 0.503722\n",
      "[58]\tvalid_0's multi_logloss: 0.50422\n",
      "[59]\tvalid_0's multi_logloss: 0.504806\n",
      "[60]\tvalid_0's multi_logloss: 0.505309\n",
      "[61]\tvalid_0's multi_logloss: 0.50582\n",
      "[62]\tvalid_0's multi_logloss: 0.506401\n",
      "[63]\tvalid_0's multi_logloss: 0.506916\n",
      "[64]\tvalid_0's multi_logloss: 0.507431\n",
      "[65]\tvalid_0's multi_logloss: 0.507957\n",
      "[66]\tvalid_0's multi_logloss: 0.508558\n",
      "[67]\tvalid_0's multi_logloss: 0.509086\n",
      "[68]\tvalid_0's multi_logloss: 0.509618\n",
      "[69]\tvalid_0's multi_logloss: 0.510154\n",
      "[70]\tvalid_0's multi_logloss: 0.510704\n",
      "[71]\tvalid_0's multi_logloss: 0.511318\n",
      "[72]\tvalid_0's multi_logloss: 0.51187\n",
      "[73]\tvalid_0's multi_logloss: 0.512414\n",
      "[74]\tvalid_0's multi_logloss: 0.51297\n",
      "[75]\tvalid_0's multi_logloss: 0.513526\n",
      "[76]\tvalid_0's multi_logloss: 0.514138\n",
      "[77]\tvalid_0's multi_logloss: 0.514692\n",
      "[78]\tvalid_0's multi_logloss: 0.515119\n",
      "[79]\tvalid_0's multi_logloss: 0.515679\n",
      "[80]\tvalid_0's multi_logloss: 0.516111\n",
      "[81]\tvalid_0's multi_logloss: 0.516736\n",
      "[82]\tvalid_0's multi_logloss: 0.517221\n",
      "[83]\tvalid_0's multi_logloss: 0.517325\n",
      "[84]\tvalid_0's multi_logloss: 0.517803\n",
      "[85]\tvalid_0's multi_logloss: 0.51796\n",
      "[86]\tvalid_0's multi_logloss: 0.518101\n",
      "[87]\tvalid_0's multi_logloss: 0.518722\n",
      "[88]\tvalid_0's multi_logloss: 0.518738\n",
      "[89]\tvalid_0's multi_logloss: 0.519309\n",
      "[90]\tvalid_0's multi_logloss: 0.51939\n",
      "[91]\tvalid_0's multi_logloss: 0.519964\n",
      "[92]\tvalid_0's multi_logloss: 0.520431\n",
      "[93]\tvalid_0's multi_logloss: 0.521063\n",
      "[94]\tvalid_0's multi_logloss: 0.521499\n",
      "[95]\tvalid_0's multi_logloss: 0.522064\n",
      "[96]\tvalid_0's multi_logloss: 0.522564\n",
      "[97]\tvalid_0's multi_logloss: 0.523141\n",
      "[98]\tvalid_0's multi_logloss: 0.523645\n",
      "[99]\tvalid_0's multi_logloss: 0.524217\n",
      "[100]\tvalid_0's multi_logloss: 0.524712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "        n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm = lgb.LGBMClassifier()\n",
    "gbm.fit(S_train, y_train, eval_set=[(S_test, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8615179760319573"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gbm.predict(S_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
